import requests
import json
from datetime import datetime
from pathlib import Path
# üìÇ ƒê·∫∑t th∆∞ m·ª•c l∆∞u file ƒë·∫ßu ra
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(exist_ok=True)
SOURCES = [
    {"name": "Socolive", "url": "https://hxcv.site/socolive", "output": OUTPUT_DIR /"socolive.m3u"},
    {"name": "Hoadao", "url": "https://hxcv.site/hoadao", "output": OUTPUT_DIR /"hoadao.m3u"},
    {"name": "Vankhanh", "url": "https://hxcv.site/vankhanh", "output": OUTPUT_DIR /"vankhanh.m3u"},
    {"name": "Chuoichien", "url": "https://hxcv.site/chuoichien", "output": OUTPUT_DIR /"chuoichien.m3u"},
    {"name": "LuongSon", "url": "https://hxcv.site/luongson", "output": OUTPUT_DIR /"luongson.m3u"},
    # {"name": "KhanDaiA", "url": "https://hxcv.site/khandaia", "output": OUTPUT_DIR /"khandaia.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c
    # {"name": "BunCha", "url": "https://hxcv.site/buncha", "output": OUTPUT_DIR /"buncha.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c
    {"name": "GaVang", "url": "https://hxcv.site/gavang", "output": OUTPUT_DIR /"gavang.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c
]

ALL_OUTPUT = OUTPUT_DIR / "all.m3u"

def fetch_json(url):
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"‚ùå L·ªói l·∫•y JSON t·ª´ {url}: {e}")
        return None

def fetch_stream_links(remote_url):
    data = fetch_json(remote_url)
    if not data or "stream_links" not in data:
        return []
    links = []
    for s in data.get("stream_links", []):
        if not s.get("url"):
            continue
        headers = {h["key"]: h["value"] for h in s.get("request_headers", [])}
        links.append({
            "name": s.get("name", "Unnamed"),
            "url": s["url"],
            "referer": headers.get("Referer")
        })
    return links

def extract_channels(data):
    channels = []
    def walk(node):
        if isinstance(node, dict):
            if "channels" in node:
                channels.extend(node["channels"])
            for v in node.values():
                walk(v)
        elif isinstance(node, list):
            for item in node:
                walk(item)
    walk(data)
    return channels

def process_source(name, base_url, output_file):
    print(f"\n==============================")
    print(f"üõ∞Ô∏è  ƒêang x·ª≠ l√Ω ngu·ªìn {name}: {base_url}")
    print(f"==============================")

    root = fetch_json(base_url)
    if not root:
        print(f"‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ {base_url}")
        return []

    channels = extract_channels(root)
    if not channels:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y channel n√†o trong {name}")
        return []

    all_entries = []

    for ch in channels:
        match_name = ch.get("name", "NoName")
        img = ch.get("image", {}).get("url")
        league_name = ch.get("league_name") or ch.get("category") or "Unknown League"

        # Gi·ªù thi ƒë·∫•u
        time_str = ch.get("start_time") or ch.get("time") or ""
        if time_str:
            try:
                dt = datetime.fromisoformat(time_str.replace("Z", "+00:00"))
                local_time = dt.astimezone().strftime("%H:%M")
            except Exception:
                local_time = time_str
            match_label = f"{match_name} - {local_time}"
        else:
            match_label = match_name

        print(f"\n‚öΩ {match_label} ({league_name})")
        match_entries = []

        for source in ch.get("sources", []):
            for content in source.get("contents", []):
                for stream in content.get("streams", []):
                    blv_name = stream.get("name", "").strip() or "No BLV"
                    remote_url = stream.get("remote_data", {}).get("url")
                    if not remote_url:
                        continue

                    links = fetch_stream_links(remote_url)
                    if not links:
                        continue

                    print(f"   ‚Ä¢ {blv_name}: {len(links)} link(s)")
                    for link in links:
                        match_entries.append({
                            "source": name,
                            "league": league_name,
                            "match": match_label,
                            "name": f"{match_label} [{blv_name} - {link['name']}]",
                            "url": link["url"],
                            "referer": link["referer"],
                            "img": img
                        })

        if not match_entries:
            print("   ‚ö†Ô∏è  Kh√¥ng c√≥ stream h·ª£p l·ªá.")
            continue

        all_entries.extend(match_entries)

    # Vi·∫øt file ri√™ng
    if all_entries:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for e in all_entries:
                attrs = [
                    f'group-title="{e["league"]} ‚ñ∏ {e["match"]}"'
                ]
                if e["img"]:
                    attrs.append(f'tvg-logo="{e["img"]}"')
                if e["referer"]:
                    attrs.append(f'referer="{e["referer"]}"')
                attr_line = " ".join(attrs)
                f.write(f'#EXTINF:-1 {attr_line},{e["name"]}\n')
                f.write(f'{e["url"]}\n')

        print(f"üéâ ƒê√£ t·∫°o xong file: {output_file} ({len(all_entries)} links)")
    else:
        print(f"‚ö†Ô∏è Kh√¥ng c√≥ link h·ª£p l·ªá cho {name}")

    return all_entries

def generate_all_playlist(all_data):
    print("\n==============================")
    print("üß© G·ªôp t·∫•t c·∫£ ngu·ªìn th√†nh all.m3u (chia theo ngu·ªìn & tr·∫≠n)")
    print("==============================")

    with open(ALL_OUTPUT, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for e in all_data:
            # G·ªôp 3 c·∫•p: Source ‚ñ∏ League ‚ñ∏ Match
            group = f'{e["source"]} ‚ñ∏ {e["league"]} ‚ñ∏ {e["match"]}'
            attrs = [f'group-title="{group}"']
            if e["img"]:
                attrs.append(f'tvg-logo="{e["img"]}"')
            if e["referer"]:
                attrs.append(f'referer="{e["referer"]}"')
            attr_line = " ".join(attrs)
            f.write(f'#EXTINF:-1 {attr_line},{e["name"]}\n')
            f.write(f'{e["url"]}\n')

    print(f"üéâ ƒê√£ t·∫°o xong file t·ªïng: {ALL_OUTPUT} ({len(all_data)} links)")

def main():
    all_entries = []
    Path("./").mkdir(exist_ok=True)

    for src in SOURCES:
        entries = process_source(src["name"], src["url"], src["output"])
        all_entries.extend(entries)

    if all_entries:
        generate_all_playlist(all_entries)
    else:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá n√†o ƒë·ªÉ g·ªôp.")

    if not any(OUTPUT_DIR.glob("*.m3u")):
        print("‚ö†Ô∏è Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c t·∫°o trong output/. Ki·ªÉm tra ngu·ªìn d·ªØ li·ªáu!")
    
    # üßÆ Ghi th·ªëng k√™ ƒë·ªÉ workflow d√πng trong commit message
    stats_file = OUTPUT_DIR / "stats.txt"
    with open(stats_file, "w", encoding="utf-8") as f:
        f.write(str(len(all_entries)))

if __name__ == "__main__":
    main()
    

