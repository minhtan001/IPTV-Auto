import requests
import json
from datetime import datetime
from pathlib import Path

# üìÇ ƒê·∫∑t th∆∞ m·ª•c l∆∞u file ƒë·∫ßu ra
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(exist_ok=True)

SOURCES = [
    # {"name": "BunCha", "url": "https://hxcv.site/buncha", "output": OUTPUT_DIR /"buncha.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c
    {"name": "KhanDaiA", "url": "https://hxcv.site/khandaia", "output": OUTPUT_DIR /"khandaia.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c, ch·∫°y v·ªõi vlc th√¨ ok    
    {"name": "GaVang", "url": "https://hxcv.site/gavang", "output": OUTPUT_DIR /"gavang.m3u"}, # ch∆∞a ch·∫°y ƒë∆∞·ª£c, ch·∫°y v·ªõi vlc th√¨ ok
    {"name": "Socolive", "url": "https://hxcv.site/socolive", "output": OUTPUT_DIR /"socolive.m3u"},
    {"name": "Hoadao", "url": "https://hxcv.site/hoadao", "output": OUTPUT_DIR /"hoadao.m3u"},
    {"name": "Vankhanh", "url": "https://hxcv.site/vankhanh", "output": OUTPUT_DIR /"vankhanh.m3u"},
    {"name": "Chuoichien", "url": "https://hxcv.site/chuoichien", "output": OUTPUT_DIR /"chuoichien.m3u"},
    {"name": "LuongSon", "url": "https://hxcv.site/luongson", "output": OUTPUT_DIR /"luongson.m3u"},    
    {"name": "TruyenHinh", "url": "https://iptv.nhadai.org/v1", "output": OUTPUT_DIR /"nhadai.m3u"},
]
# üÜï C√°c ngu·ªìn ki·ªÉu M3U tr·ª±c ti·∫øp (v√≠ d·ª•: Cakhia)
EXTRA_SOURCES = [
    {"name": "Cakhia", "url": "http://sharing.gotdns.ch:8091/cakhia.php", "output": OUTPUT_DIR / "cakhia.m3u"},
    {"name": "LuongSon_2", "url": "http://sharing.gotdns.ch:8091/luongsontv.php", "output": OUTPUT_DIR / "luongson_share.m3u"}, 
    {"name": "Socolive_2", "url": "http://sharing.gotdns.ch:8091/socolive.php", "output": OUTPUT_DIR / "Socolive_share.m3u"},
    {"name": "TruyenHinh_2", "url": "https://raw.githubusercontent.com/vuminhthanh12/vuminhthanh12/refs/heads/main/vmttv", "output": OUTPUT_DIR / "nhadai_2.m3u"},
]
ALL_OUTPUT = OUTPUT_DIR / "all.m3u"


def fetch_json(url):
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"‚ùå L·ªói l·∫•y JSON t·ª´ {url}: {e}")
        return None


def fetch_stream_links(remote_url):
    """L·∫•y danh s√°ch link stream t·ª´ remote_data (d√†nh cho ngu·ªìn c≈©)."""
    data = fetch_json(remote_url)
    if not data or "stream_links" not in data:
        return []
    links = []
    for s in data.get("stream_links", []):
        if not s.get("url"):
            continue
        headers = {h["key"]: h["value"] for h in s.get("request_headers", [])}
        links.append({
            "name": s.get("name", "Unnamed"),
            "url": s["url"],
            "referer": headers.get("Referer")
        })
    return links


def extract_channels(data):
    """T√¨m to√†n b·ªô channel trong JSON, d√π n·∫±m trong group ho·∫∑c root."""
    channels = []

    def walk(node):
        if isinstance(node, dict):
            if "channels" in node:
                channels.extend(node["channels"])
            for v in node.values():
                walk(v)
        elif isinstance(node, list):
            for item in node:
                walk(item)

    walk(data)
    return channels


def process_source(name, base_url, output_file):
    print(f"\n==============================")
    print(f"üõ∞Ô∏è  ƒêang x·ª≠ l√Ω ngu·ªìn {name}: {base_url}")
    print(f"==============================")

    root = fetch_json(base_url)
    if not root:
        print(f"‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ {base_url}")
        return []

    channels = extract_channels(root)
    if not channels:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y channel n√†o trong {name}")
        return []

    all_entries = []

    for ch in channels:
        match_name = ch.get("name", "NoName")
        img = (ch.get("image") or {}).get("url")

        # Gi·ªù thi ƒë·∫•u
        time_str = ch.get("start_time") or ch.get("time") or ""
        if time_str:
            try:
                dt = datetime.fromisoformat(time_str.replace("Z", "+00:00"))
                local_time = dt.astimezone().strftime("%H:%M")
            except Exception:
                local_time = time_str
            match_label = f"{match_name} - {local_time}"
        else:
            match_label = match_name

        print(f"\nüì∫ {match_label}")
        match_entries = []

        for source in ch.get("sources", []):
            for content in source.get("contents", []):
                for stream in content.get("streams", []):
                    blv_name = stream.get("name", "").strip() or "No BLV"
                    img_stream = (stream.get("image") or {}).get("url")

                    # --- 1Ô∏è‚É£ X·ª≠ l√Ω ki·ªÉu c≈©: c√≥ remote_data ---
                    remote_data = stream.get("remote_data")
                    if remote_data and isinstance(remote_data, dict):
                        remote_url = remote_data.get("url")
                        if remote_url:
                            links = fetch_stream_links(remote_url)
                            for link in links:
                                match_entries.append({
                                    "source": name,
                                    "match": match_label,
                                    "name": f"{match_label} [{blv_name} - {link['name']}]",
                                    "url": link["url"],
                                    "referer": link["referer"],
                                    "img": img or img_stream
                                })

                    # --- 2Ô∏è‚É£ X·ª≠ l√Ω ki·ªÉu m·ªõi: c√≥ stream_links tr·ª±c ti·∫øp ---
                    elif "stream_links" in stream:
                        for s in stream["stream_links"]:
                            url = s.get("url")
                            if not url:
                                continue
                            match_entries.append({
                                "source": name,
                                "match": match_label,
                                "name": f"{match_label} [{s.get('name', blv_name)}]",
                                "url": url,
                                "referer": None,
                                "img": img or img_stream
                            })

        if not match_entries:
            print("   ‚ö†Ô∏è  Kh√¥ng c√≥ stream h·ª£p l·ªá.")
            continue

        all_entries.extend(match_entries)

    # Vi·∫øt file ri√™ng
    if all_entries:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for e in all_entries:
                attrs = [f'group-title="{e["match"]}"']

                # B·ªï sung t√πy ch·ªçn referer cho VLC
                if e["referer"]:
                    f.write(f'#EXTVLCOPT:http-referrer={e["referer"]}\n')
                    # T√πy ch·ªçn referer (KH√îNG ph·∫£i http-referrer) v·∫´n ƒë∆∞·ª£c gi·ªØ trong EXTINF
                    attrs.append(f'referer="{e["referer"]}"')
                if e["img"]:
                    attrs.append(f'tvg-logo="{e["img"]}"')
                attr_line = " ".join(attrs)
                f.write(f'#EXTINF:-1 {attr_line},{e["name"]}\n')
                f.write(f'{e["url"]}\n')
        print(f"üéâ ƒê√£ t·∫°o xong file: {output_file} ({len(all_entries)} links)")
    else:
        print(f"‚ö†Ô∏è Kh√¥ng c√≥ link h·ª£p l·ªá cho {name}")

    return all_entries


def process_m3u_source(name, url, output_file):
    """X·ª≠ l√Ω ngu·ªìn .m3u c√≥ ch·ª©a |Referer=..."""
    print(f"\n==============================")
    print(f"üõ∞Ô∏è  ƒêang x·ª≠ l√Ω M3U ngu·ªìn {name}: {url}")
    print(f"==============================")

    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        lines = r.text.splitlines()
    except Exception as e:
        print(f"‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c M3U t·ª´ {url}: {e}")
        return []

    all_entries = []
    current_title = "Unknown"

    for line in lines:
        if line.startswith("#EXTINF"):
            current_title = line.split(",", 1)[-1].strip()
        elif line.strip() and not line.startswith("#"):
            link = line.strip()
            ref = None
            if "|Referer=" in link:
                link, ref = link.split("|Referer=", 1)
            all_entries.append({
                "source": name,
                "match": name,
                "name": current_title,
                "url": link,
                "referer": ref,
                "img": None,
            })

    if all_entries:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for e in all_entries:
                if e["referer"]:
                    f.write(f'#EXTVLCOPT:http-referrer={e["referer"]}\n')
                f.write(f'#EXTINF:-1 group-title="{name}",{e["name"]}\n')
                f.write(f'{e["url"]}\n')
        print(f"üéâ ƒê√£ t·∫°o file M3U chu·∫©n VLC: {output_file} ({len(all_entries)} links)")
    else:
        print(f"‚ö†Ô∏è Kh√¥ng c√≥ link h·ª£p l·ªá trong {name}")

    return all_entries


def generate_all_playlist(all_data):
    print("\n==============================")
    print("üß© G·ªôp t·∫•t c·∫£ ngu·ªìn th√†nh all.m3u (group theo ngu·ªìn)")
    print("==============================")
    with open(ALL_OUTPUT, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for e in all_data:
            group = e["source"]
            attrs = [f'group-title="{group}"']
            
            # B·ªï sung t√πy ch·ªçn referer cho VLC
            if e["referer"]:
                f.write(f'#EXTVLCOPT:http-referrer={e["referer"]}\n')
                # T√πy ch·ªçn referer (KH√îNG ph·∫£i http-referrer) v·∫´n ƒë∆∞·ª£c gi·ªØ trong EXTINF
                attrs.append(f'referer="{e["referer"]}"')
            if e["img"]:
                attrs.append(f'tvg-logo="{e["img"]}"')
            attr_line = " ".join(attrs)
            f.write(f'#EXTINF:-1 {attr_line},{e["name"]}\n')
            f.write(f'{e["url"]}\n')

    print(f"üéâ ƒê√£ t·∫°o xong file t·ªïng: {ALL_OUTPUT} ({len(all_data)} links)")


def main():
    all_entries = []
    Path("./").mkdir(exist_ok=True)

    # JSON/remote data sources
    for src in SOURCES:
        entries = process_source(src["name"], src["url"], src["output"])
        all_entries.extend(entries)

    # Extra M3U sources (Cakhia, ...)
    for src in EXTRA_SOURCES:
        entries = process_m3u_source(src["name"], src["url"], src["output"])
        all_entries.extend(entries)

    if all_entries:
        generate_all_playlist(all_entries)
    else:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá n√†o ƒë·ªÉ g·ªôp.")

    if not any(OUTPUT_DIR.glob("*.m3u")):
        print("‚ö†Ô∏è Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c t·∫°o trong output/. Ki·ªÉm tra ngu·ªìn d·ªØ li·ªáu!")
    
    # üßÆ Ghi th·ªëng k√™ ƒë·ªÉ workflow d√πng trong commit message
    stats_file = OUTPUT_DIR / "stats.txt"
    with open(stats_file, "w", encoding="utf-8") as f:
        f.write(str(len(all_entries)))


if __name__ == "__main__":
    main()
